<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Kun Zhou, Assistant Professor (Hundred Talents Program), Shenzhen University">
<meta name="description" content="Kun Zhou&#39;s home page">
<meta name="google-site-verification" content="X2QFrl-bPeg9AdlMt4VKT9v6MJUSTCf-SrY3CvKt4Zs" /> 
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Kun Zhou&#39;s Homepage</title>
<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-159069803-1', 'auto');
ga('send', 'pageview');
</script>
<!-- End Google Analytics -->
<!--
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');

</script>
-->
</head>
<body>
<div id="layout-content" style="margin-top:25px">
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">
					<h1>Kun Zhou<font face="Arial">    周昆 </font></h1></div>

				<h3>Ph.D.</h3>
				<p>
					Dept. of Computer and Information Engineering <br>
					The Chinese University of Hong Kong(Shenzhen) <br>
					Shenzhen, Guangdong, China<br>
					<br>
					Email-1: <a href="zhoukun303808@gmail.com">zhoukun303808 AT gmail DOT com</a><br>
					Email-1: <a href="kunzhou@link.cuhk.edu.cn">kunzhou AT link DOT cuhk DOT edu DOT cn</a><br>
				</p>
				<p>
					<a href="https://github.com/redrock303"><img src="./pic/others/github_logo.png" height="30px"></a>&nbsp;&nbsp;
					<!--<a href="https://scholar.google.com/citations?user=R8mtv14AAAAJ&hl=en&oi=sra"><img src="./pic/others/google_scholar_logo.png" height="30px"></a>&nbsp;&nbsp;-->
				</p>
				</p>
			</td>
			<td>
				<img src="./pic/zhoukun.jpg" border="0" width="220"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>

<!--<h2>Biography [<a href="./CV-JinYueming.pdf">CV</a>]</h2>-->
<h2>Biography </h2>
<p>
	I obtained my Ph.D. in the Department of SSE, the Chinese University of Hong Kong(Shenzhen),
	under the supervision of <a href="https://sse.cuhk.edu.cn/en/faculty/hanxiaoguang/">Prof. Xiaoguang Han</a> and <a href="https://sites.google.com/site/jiangbolu/">Prof. Jiangbo Lu</a>. 
	My research interests lie primarily in computer vision and machine learning. I have done some works about 3d human pose and shape estimation, super-resolution, inpainting, video restoration and frame interpolation. <!--From 2019 to present, I have collaborated with several researchers in Tencent.-->
	<br>
	<!--<br>
	In addition to the PhD candidate, I'm an amateur photographer, filmmaking learner, cooking lover, guitar learner, day dreamer, etc. I'm currently building <i><b>my own Gallery Website</b></i> (work in process) to show some of my photographs completed in these recent years.
	-->
</p>

<a href="pic/others/zk.pdf" target="_blank">CV</a>

<h2>News</h2>
<ul>
	<li>
		[07/2025] One paper is accepted by BMVC 2025.
	</li>
	<li>
		[05/2025] One paper is accepted by IJCAI 2025. One paper is accepted by ICME 2025.
	</li>
	<li>
		[02/2025] Two papers are accepted by CVPR 2025.
	</li>
	<li>
		[09/2024] One paper is accepted by NeurIPS 2024.
	</li>
	<li>
		[06/2024] One paper is accepted by ECCV 2024.
	</li>
	<li>
		[12/2023] One paper is accepted by TPAMI 2023.
	</li>
	<li>
		[06/2022] Two papers are accepted by CVPR 2022. And one (MAT) is selected in the <b>CVPR 2022 Best Paper Finalists</b>.
	</li>
	<li>
		[1/2021] One paper is accepted by TPAMI 2021.
	</li>
</ul>






<h2> Selected Publications [<a href="https://scholar.google.com/citations?user=OXCWQz0AAAAJ&hl=en">Google Scholar</a>]</h2>

<p></p>
	T-PAMI(2), CVPR(6), NeurIPS(2), ICCV(1), ECCV(1), AAAI(1), ICLR(1), IJCAI(1), ICME(1).
</p>
<table id="tbPublications" width="100%" style="border-collapse:separate; border-spacing:0px 10px;">
	<tbody>
		<tr>

		</tr>
			<td><center><img width="250" src="./pic/papers/UPS.png"></center></td>
			<td>
				<font size="2">UPS: Unified Projection Sharing for Lightweight Single-Image Super-resolution and Beyond
				<br>
				<i><b>Kun Zhou</b>,Xinyu Lin, Zhonghang Liu, Xiaoguang Han, Jiangbo Lu</i>
				<br>
				Conference on Neural Information Processing Systems (<b>NeurIPS</b>) 2024
				<br> 
			</td>
		</tr>
		<tr>
			<td><center><img width="250" src="./pic/papers/llie.png"></center></td>
			<td>
				<font size="2">Unveiling Advanced Frequency Disentanglement Paradigm for Low-Light Image Enhancement
				<br>
				<i><b>Kun Zhou</b>,Xinyu Lin, Wenbo Li, Xiaogang Xu, Yuanhao Cai, Zhonghang Liu, Xiaoguang Han, Jiangbo Lu</i>
				<br>
				Proceedings of the European Conference on Computer Vision (<b>ECCV</b>) 2024
				<br> 
				[<a href='https://arxiv.org/pdf/2409.01641v1'><b>paper</b></a>|<a href='https://github.com/redrock303/ADF-LLIE'><b>code</b></a>]

				<br>
				<b>Enhancing any LLIE frameworks and significantly (up to +7dB) with only extra 88K parameters</b>.
				<br> 
			</td>
		</tr>

		<tr>
			<td><center><img width="250" src="./pic/papers/nerflix_plus.png"></center></td>
			<td>
				<font size="2">From NeRFLiX to NeRFLiX++: A General NeRF-Agnostic Restorer Paradigm
				<br>
				<i><b>Kun Zhou</b>, Wenbo Li, Nianjuan Jiang, Xiaoguang Han, Jiangbo Lu</i>
				<br>
				IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>) 2023
				<br> 
				<br>
				<b>Restoring HQ 4K novel views from any NeRF or even GS models</b>.
				<br> 
				[<a href='https://redrock303.github.io/nerflix_plus/'><b>project</b></a>|<a href='https://ieeexplore.ieee.org/document/10361604'><b>paper</b></a>|<a href='https://www.youtube.com/watch?v=YiXvgQXiWII'><b>Video Demo</b></a>]
			</td>
		</tr>

		<tr>
			<td><center><img width="250" src="./pic/papers/nerflix.jpg"></center></td>
			<td>
				<font size="2">NeRFLiX: High-Quality Neural View Synthesis by Learning a Degradation-Driven Inter-viewpoint MiXer
				<br>
				<i><b>Kun Zhou*</b>, Wenbo Li*, Yi Wang, Tao Hu, Nianjuan Jiang, Xiaoguang Han, Jiangbo Lu</i>
				<br>
				IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2023 
				<br>
				<br>
				<b>The first general NeRF enhancer</b>.
				<br> 
				[<a href='https://redrock303.github.io/nerflix/'><b>project</b></a>|<a href='https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_NeRFLix_High-Quality_Neural_View_Synthesis_by_Learning_a_Degradation-Driven_Inter-Viewpoint_CVPR_2023_paper.pdf'><b>paper</b></a>|<a href='https://cvpr2023.thecvf.com/media/cvpr-2023/Slides/22563_oXcGfeW.pdf'><b>Slides</b></a>|<a href='https://github.com/redrock303/NeRFLiX_CPVR2023'><b>code</b></a>]<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/redrock303/NeRFLiX_CPVR2023?style=social">
			</td>
		</tr>
	
		<tr>
			<td><center><img width="250" src="./pic/papers/tcl.jpg"></center></td>
			<td>
				<font size="2">Exploring Motion Ambiguity and Alignment for High-Quality Video Frame Interpolation
				<br>
				<i><b>Kun Zhou</b> , Wenbo Li, Xiaoguang Han, Jiangbo Lu</i>
				<br>
				IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2023
				<br>
				[<a href='https://arxiv.org/pdf/2203.10291'><b>paper</b></a>]
			</td>
		</tr>
		
		<td><center><img width="250" src="./pic/papers/rta.jpg"></center></td>
		<td>
			<font size="2">Revisiting Temporal Alignment for Video Restoration
			<br>
			<i><b>Kun Zhou*</b>, Wenbo Li*, Liying Lu, Xiaoguang Han, Jiangbo Lu</i>
			<br>
			IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2022
			<br>
			[<a href='https://arxiv.org/abs/2111.15288'><b>paper</b></a>|<a href='https://github.com/redrock303/Revisiting-Temporal-Alignment-for-Video-Restoration'><b>code</b></a>]  <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/redrock303/Revisiting-Temporal-Alignment-for-Video-Restoration?style=social">
		</td>
	</tr>

	<tr></tr>
		<td><center><img width="250" src="./pic/papers/HEMlets_posh.png"></center></td>
		<td>
			<font size="2">HEMlets posh: learning part-centric heatmap triplets for 3D human pose and shape estimation
			<br>
			<i><b>Kun Zhou</b>, Xiaoguang Han, Nianjuan Jiang, Kui Jia, Jiangbo Lu</i>
			<br>
			IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>) 2021
			<br>
			[<a href='https://ieeexplore.ieee.org/abstract/document/9320561/'><b>paper</b></a>]
		</td>
	</tr>

	<tr></tr>
		<td><center><img width="250" src="./pic/papers/HEMlets_pose.jpg"></center></td>
		<td>
			<font size="2">Hemlets pose: Learning part-centric heatmap triplets for accurate 3d human pose estimation
			<br>
			<i><b>Kun Zhou</b>, Xiaoguang Han, Nianjuan Jiang, Kui Jia, Jiangbo Lu</i>
			<br>
			International Conference on Computer Vision (<b>ICCV</b>) 2019
			<br> 
			[<a href='https://sites.google.com/site/hemletspose/'><b>project</b></a>|<a href='http://openaccess.thecvf.com/content_ICCV_2019/papers/Zhou_HEMlets_Pose_Learning_Part-Centric_Heatmap_Triplets_for_Accurate_3D_Human_ICCV_2019_paper.pdf'><b>paper</b></a>|<a href='https://github.com/redrock303/HEMlets'><b>code</b></a>] <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/redrock303/HEMlets?style=social">
		</td>
	</tr>

	<tr></tr>
		<td><center><img width="250" src="./pic/papers/bebygan.jpg"></center></td>
		<td>
			<font size="2">Best-Buddy GANs for Highly Detailed Image Super-Resolution
			<br>
			<i>Wenbo Li*, <b>Kun Zhou*</b>, Lu Qi, Liying Lu, Jiangbo Lu, Jiaya Jia</i>
			<br>
			Thirty-Sixth AAAI Conference on Artificial Intelligence (<b>AAAI</b>) 2022 (<b>Oral</b>)
			<br>
			[<a href='https://arxiv.org/abs/2103.15295'><b>paper</b></a>|<a href='https://github.com/dvlab-research/Simple-SR'><b>code</b></a>]  <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/dvlab-research/Simple-SR?style=social">
		</td>
	</tr>
	<tr></tr>
		<td><center><img width="250" src="./pic/papers/lapar.jpg"></center></td>
		<td>
			<font size="2">LAPAR: Linearly-Assembled Pixel-Adaptive Regression Network for Single Image Super-resolution and Beyond
			<br>
			<i>Wenbo Li*, <b>Kun Zhou*</b>, Lu Qi, Nianjuan Jiang, Jiangbo Lu, Jiaya Jia</i>
			<br>
			Advances in Neural Information Processing Systems (<b>NeurIPS</b>) 2020
			<br>
			[<a href='https://arxiv.org/abs/2105.10422'><b>paper</b></a>|<a href='https://github.com/dvlab-research/Simple-SR'><b>code</b></a>]  <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/dvlab-research/Simple-SR?style=social">
		</td>
	</tr>
	<tr>
		<td><center><img width="250" src="./pic/papers/sdm.jpg"></center></td>
		<td>
			<font size="2">Image Inpainting via Iteratively Decoupled Probabilistic Modeling
			<br>
			<i>Wenbo Li, Xin Yu, <b>Kun Zhou</b> , Yibing Song, Zhe Lin, Jiaya Jia</i>
			<br>
				arXiv:2212.02963
			<br>
			[<a href='https://arxiv.org/abs/2212.02963'><b>paper</b></a>|<a href='https://github.com/fenglinglwb/SDM'><b>code</b></a>]  <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/fenglinglwb/SDM?style=social">
		</td>
	</tr>


	<tr>
		<td><center><img width="250" src="./pic/papers/mat.jpg"></center></td>
		<td>
			<font size="2">MAT: Mask-Aware Transformer for Large Hole Image Inpainting
			<br>
			<i>Wenbo Li, Zhe Lin, <b>Kun Zhou</b>, Lu Qi, Yi Wang, Jiaya Jia</i>
			<br>
			IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2022 (<b>Best Paper Finalists, Oral</b>)
			<br>
			[<a href='https://arxiv.org/abs/2203.15270'><b>paper</b></a>|<a href='https://github.com/fenglinglwb/MAT'><b>code</b></a>|<a href='https://www.youtube.com/watch?v=9foscNsObMA'><b>Media Report</b></a>|<a href='https://docs.google.com/presentation/d/190LNr2_d384OL92WGgfHwUkRUCpEIECy/edit?usp=sharing&ouid=115198583208219285057&rtpof=true&sd=true'><b>Slides</b></a>|<a href='https://drive.google.com/file/d/1Yjq6wqnA9CGDwGbeba51Sen76HnbaRnw/view?usp=sharing'><b>Poster</b></a>]  <img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/fenglinglwb/MAT?style=social">
		</td>
	</tr>

	<tr>
		

	

	<tr>
		<td><center><img width="250" src="./pic/papers/lle.png"></center></td>
		<td>
			<font size="2">Mutual Guidance and Residual Integration for Image Enhancement
			<br>
			<i><b>Kun Zhou</b>, Wenbo Li, Xiaoguang Han, Jiangbo Lu</i>
			<br>
            arXiv:2211.13919
			<br>
			[<a href='https://arxiv.org/abs/2211.13919'><b>paper</b></a>]  
		</td>
	</tr>

	

	




	

	<tr>
		<td><center><img width="250" src="./pic/papers/eccv18.jpg"></center></td>
		<td>
			<font size="2">Adversarial 3d human pose estimation via multimodal depth supervision
			<br>
			<i><b>Kun Zhou</b>, Jinmiao Cai, Yao Li, Yulong Shi, Xiaoguang Han, Nianjuan Jiang, Kui Jia, Jiangbo Lu</i>
			<br>
			Ranked fourth in the ECCV2018 PoseTrack Challenge.
			<br>
			[<a href='https://arxiv.org/abs/1809.07921'><b>paper</b></a>]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/fbi.jpg"></center></td>
		<td>
			<font size="2">Fbi-pose: Towards bridging the gap between 2d images and 3d human poses using forward-or-backward information
			<br>
			<i>Yulong Shi, Xiaoguang Han, Nianjuan Jiang, <b>Kun Zhou</b> , Kui Jia, Jiangbo Lu</i>
			<br>
			 In 2018, Fbi-pose achieved the <b>top ranking</b> on the Human3.6M Benchmark (H36M_NOS10).
			<br>
			[<a href='https://arxiv.org/abs/1806.09241'><b>paper</b></a>]
		</td>
	</tr>

	<tr>
		<td><center><img width="250" src="./pic/papers/cloth.png"></center></td>
		<td>
			<font size="2">Real-time collision detection method for fluid and cloth
			<br>
			<i>Hui Zang，Zhen Liu, Yanjie Chai，Tingting Liu, <b>Kun Zhou</b></i>
			<br>
            Journal of Computer Aided Design and Graphics 2018
			<br>
			[<a href='https://scholar.google.com/scholar?cluster=16400719484130216203&hl=en&oi=scholarr'><b>paper</b></a>]
		</td>
	</tr>
    </tbody>
</table>


<h2><font> Talk</font></h2>
<ul>
<!--<ul style="list-style-type:none"> https://www.bilibili.com/video/BV1e3411p7vE/?spm_id_from=333.999.0.0
<p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font size="3"><meta charset="utf-8">-->
    <li>
		<a href='https://www.bilibili.com/video/BV1e3411p7vE/?spm_id_from=333.999.0.0'><b>AI-Time--Computer vision issues in the process of intelligent manufacturing industry upgrading</b></a> 
    </li>
    <!--  </font> </p> -->
</ul>



<h2><font> Academic Service </font></h2>
<ul>
	<b>Conference Program Committee :</b></br>
    AAAI</br>
</br>

    <b>Journal Reviewer:</b></br>
    IJCV</br>
    TIP</br>
    TSMC</br>
    TVGC</br>
	ESWA</br>
    </br>

    <b>Conference Reviewer:</b></br>
    NeurIPS</br>
    CVPR</br>
    ICCV</br>
	ICLR</br>
	ECCV</br>
	ACCV</br>
	ICME</br>
</ul>


<p align=right>
	<a class="pull-right" href="#">
		<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=9n4x1ez8R2TqzDAL31HNW7STql-oJXmX3Q338AUgvfY&cl=ffffff&w=a"></script>
	</a>
</p>

<p><center><font>
        <br>&copy; Kun Zhou | Last updated: June. 2023  </font></center>
</p>

</div>
</body></html>
